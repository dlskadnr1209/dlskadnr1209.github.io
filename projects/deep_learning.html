<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Deep Learning</title>
    <link rel="stylesheet" href="/style.css">
    <script src="/script.js"></script>
</head>
<body>
    <div w3-include-html="/header.html"></div>
    <div w3-include-html="/nav.html"></div>
    <div class="project" id="projects">
        <h1>Deep Learning</h1>
        <h2>Introduction</h2>
        <p>&nbsp;SKA-SDC3a (Square Kilometre Array Science Data Challenge 3a) is a part of the broader SKA Science Data Challenge 3 (SDC3) aimed at preparing the astronomical community for the novel and complex data anticipated from the Square Kilometre Array (SKA). The "Foregrounds" challenge, or SDC3a, requires participants to remove obscuring sources of emission to reveal the underlying hydrogen-21cm signal from the Epoch of Reionisation (EoR). This foreground emission comes from both Galactic and extragalactic sources, so this work include elimination of galactic and extragalactic sources from observational data. <a href="https://sdc3.skao.int/challenges/foregrounds" target="_blank">Reference</a><br><br>
        &nbsp;Deep learning is being introduced across all research fields, yielding significant results. As an attempt, this project used deep learning to remove foreground signals for early universe signal observation. The background was simulated, and celestial objects were randomly added to create training sets. The upscaling process involved bicubic interpolation, and data augmentation was achieved through rotation and translation, providing an understanding of various algorithms for image data processing. Additionally, using Python's TensorFlow package, the project applied a u-NET structure based on an autoencoder model to extract only the background from 3D cubes containing celestial bodies. </p>
        <h2>Methodology</h2>
        <p>&nbsp;Diffuse emission were generated by <a href="https://github.com/telegraphic/pygdsm" target="_blank">Pygdsm</a> 2016 model. In addition, astrophysical point sources cube was added. Deep Learning Structure is as follows.<br><br>
	<b>Encoding Layers:</b></p><br>
        <ul>
            <li><b>Encoding 1:</b> Conv3D -> BatchNormalization -> ReLU -> MaxPooling3D</li>
            <li><b>Encoding 2:</b> Conv3D -> BatchNormalization -> ReLU -> MaxPooling3D</li>
            <li><b>Encoding 3:</b> Conv3D -> BatchNormalization -> ReLU -> MaxPooling3D</li>
            <li><b>Encoding 4:</b> Conv3D -> BatchNormalization -> ReLU -> MaxPooling3D</li>
            <li><b>Encoding 5:</b> Conv3D -> BatchNormalization -> ReLU</li>
        </ul>
	<p><b>Input shape : (128, 128, 128, 1)</b></p>

	<p><b>Decoding Layers:</b></p><br>
        <ul>
            <li><b>Decoding 1:</b> UpSampling3D -> Concatenate -> Conv3D -> ReLU</li>
            <li><b>Decoding 2:</b> UpSampling3D -> Concatenate -> Conv3D -> ReLU</li>
            <li><b>Decoding 3:</b> UpSampling3D -> Concatenate -> Conv3D -> ReLU</li>
            <li><b>Decoding 4:</b> UpSampling3D -> Concatenate -> Conv3D -> ReLU</li>
            <li><b>Final Block:</b> Conv3D with 1 filter and tanh activation</li>
        </ul>
	<p><b>Output shape : (128, 128, 128, 1)</b></p>
        <p>As shown here, we use 128 3D cubes for our project which need huge computational resources.</p>
        </p>
        <h2>Github</h2>
        <p>&nbsp;<a href="https://github.com/dlskadnr1209/SDC3a_3dDL" target="_blank">View the project on GitHub</a> Result : Modlel_Analysis.ipynb </p>
        <h2>Comment</h2>
        <p>&nbsp;Extracting point-like sources signal could be important because one of the interest of astrophysics is large-scale diffuse emission such as radio relics, filament structures, and so on. This project is expected to be initial step to apply deep learning based method to astronomical data. Anyone can use this pipeline freely! </p>
    </div>
    <div w3-include-html="/footer.html"></div>
    <script>
        includeHTML();
    </script>
</body>
</html>

